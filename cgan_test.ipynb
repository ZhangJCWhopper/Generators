{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import loadIvs_test\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "iv_params = {\n",
    "    \"short_ivs_dir\": \"/work/jiacen/ivectors\",\n",
    "    \"long_ivs_dir\": \"/work/jiacen/long_ivectors\",\n",
    "    \"task_type\": \"test\",\n",
    "    \"batch_size\": batch_size,\n",
    "}\n",
    "\n",
    "ivectors = loadIvs_test.IvectorLoader(**iv_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def glorot_init(shape, dtype, partition_info=None):\n",
    "    with tf.name_scope(\"glorot_init\"):\n",
    "        return tf.random_normal(shape=shape, stddev=1./tf.sqrt(shape[0]/2.), dtype=dtype)\n",
    "\n",
    "def lrelu(x, a=0.2):\n",
    "    with tf.name_scope(\"leaky_relu\"):\n",
    "        return tf.nn.relu(tf.maximum(x, a*x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.import_meta_graph(\"/work/jiacen/wooo/tfmodels/cgan-model-1000000.meta\")\n",
    "saver.restore(sess, tf.train.latest_checkpoint(\"/work/jiacen/wooo/tfmodels/.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_dim=400\n",
    "input_dim = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator_test_all(x, z):\n",
    "    input_data = x+z\n",
    "    layers = [input_data]\n",
    "    for i in range(0, 5):\n",
    "        kernel = graph.get_tensor_by_name(\"generator/gen%d/kernel:0\" % (i,))\n",
    "        bias = graph.get_tensor_by_name(\"generator/gen%d/bias:0\" % (i,))\n",
    "        layer = lrelu(tf.add(tf.matmul(layers[-1], kernel), bias))\n",
    "        layers.append(layer)\n",
    "    return layers\n",
    "def generator(x, z):\n",
    "    input_data = x+z\n",
    "    layers = [input_data]\n",
    "    for i in range(0, 5):\n",
    "        kernel = graph.get_tensor_by_name(\"generator/gen%d/kernel:0\" % (i,))\n",
    "        bias = graph.get_tensor_by_name(\"generator/gen%d/bias:0\" % (i,))\n",
    "        layer = lrelu(tf.add(tf.matmul(layers[-1], kernel), bias))\n",
    "        layers.append(layer)\n",
    "    return layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_data = ivectors.next_batch()\n",
    "priori = batch_data[:, 0, :]\n",
    "truth = batch_data[:, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise = np.random.normal(-1., 1., size=[32, 400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_random = tf.placeholder(tf.float32, shape=[None, noise_dim], name=\"input_random\")\n",
    "input_ivector = tf.placeholder(tf.float32, shape=[None, input_dim], name=\"input_ivector\")\n",
    "gen_sample_all = generator_test_all(input_ivector, input_random)\n",
    "gen_sample = generator(input_ivector, input_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = sess.run(gen_sample_all, feed_dict={input_random:noise, input_ivector: priori})\n",
    "for i in range(5):\n",
    "    print generated[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator_test(x):\n",
    "    layers = [x]\n",
    "    for i in range(2):\n",
    "        kernel = graph.get_tensor_by_name(\"discriminator/disc%d/kernel:0\" % (i,))\n",
    "        bias = graph.get_tensor_by_name(\"discriminator/disc%d/bias:0\" % (i,))\n",
    "        layer = lrelu(tf.add(tf.matmul(layers[-1], kernel), bias))\n",
    "        layers.append(layer)\n",
    "    kernel = graph.get_tensor_by_name(\"discriminator/disc%d/kernel:0\" % (2,))\n",
    "    bias = graph.get_tensor_by_name(\"discriminator/disc%d/bias:0\" % (2,))\n",
    "    layer = tf.sigmoid(tf.add(tf.matmul(layers[-1], kernel), bias))\n",
    "    layers.append(layer)\n",
    "    return layers\n",
    "disc_fake = discriminator_test(gen_sample)\n",
    "res = sess.run(disc_fake, feed_dict={input_random:noise, input_ivector: priori})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disc0k=sess.run(graph.get_tensor_by_name(\"discriminator/disc%d/kernel:0\" % (0,)))\n",
    "disc0b=sess.run(graph.get_tensor_by_name(\"discriminator/disc%d/bias:0\" % (0,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "disc0k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
